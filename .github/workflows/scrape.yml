name: Scrape Polla.cl Prizes

on:
  schedule:
    # Run daily at 10:00 AM Chile time (13:00 UTC)
    - cron: '0 13 * * *'
  workflow_dispatch:  # Allow manual trigger
  push:
    branches: [main]
    paths:
      - 'polla_app/**'
      - 'tests/**'
      - 'requirements*.txt'
      - '.github/workflows/scrape.yml'

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
      
      - name: Cache dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements-dev.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-
      
      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements-dev.txt
      
      - name: Install Playwright
        run: |
          python -m playwright install chromium
          python -m playwright install-deps
      
      - name: Run linting
        run: |
          black --check polla_app tests
          ruff check polla_app tests
      
      - name: Run type checking
        run: mypy polla_app
      
      - name: Run tests
        run: pytest tests -v --cov=polla_app --cov-report=xml
      
      - name: Upload coverage
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage.xml
          fail_ci_if_error: false

  scrape:
    runs-on: ubuntu-latest
    needs: test
    if: ${{ needs.test.result == 'success' && (github.event_name == 'schedule' || github.event_name == 'workflow_dispatch') }}
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
      
      - name: Cache dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-
      
      - name: Install dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Install Playwright
        run: |
          python -m playwright install chromium
          python -m playwright install-deps
      
      - name: Run scraper (alt sources)
        env:
          ALT_SOURCE_URLS: >-
            https://www.24horas.cl/24horas/site/tag/port/all/tagport_2312_1.html,
            https://www.openloto.cl/pozo-del-loto.html,
            https://resultadoslotochile.com/pozo-para-el-proximo-sorteo/
        run: |
          mkdir -p artifacts raw pipeline_state logs
          python main.py \
            --sources all \
            --retries 3 \
            --timeout 30 \
            --no-fail-fast \
            --raw-dir artifacts/raw \
            --normalized artifacts/normalized.jsonl \
            --comparison-report artifacts/comparison_report.json \
            --summary artifacts/run_summary.json \
            --state-file pipeline_state/last_run.jsonl \
            --log-file logs/run.jsonl \
            --mismatch-threshold 0.2
        continue-on-error: true
      
      - name: Upload logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: scraper-logs
          path: logs/
          retention-days: 30
      
      - name: Upload debug artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: scrape-artifacts
          path: |
            artifacts/
            logs/
            pipeline_state/
          retention-days: 7

  publish:
    needs: scrape
    if: ${{ needs.scrape.result == 'success' }}
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Download artifacts
        uses: actions/download-artifact@v4
        with:
          name: scrape-artifacts

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install minimal deps for publish
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt

      - name: Publish to Google Sheets
        env:
          GOOGLE_SERVICE_ACCOUNT_JSON: ${{ secrets.GOOGLE_CREDENTIALS }}
          GOOGLE_SPREADSHEET_ID: ${{ secrets.GOOGLE_SPREADSHEET_ID }}
        run: |
          if [ -f artifacts/normalized.jsonl ]; then \
            python tools/publish_to_sheets.py \
              --data artifacts/normalized.jsonl \
              --comparison artifacts/comparison_report.json \
              --sheet-name AltData \
              --discrepancy-tab Discrepancies; \
          else \
            echo "normalized.jsonl not found; skipping publish"; \
          fi
