# Polla App ‚Äî Alternative Lottery Source Ingestor

This project normalises **Loto Chile** results without touching `polla.cl`. It
parses public news articles (T13, 24Horas) and community aggregators to produce
a consistent JSON structure containing per-categor√≠a payouts and pr√≥ximo pozo
estimates.

## Features

- ‚úÖ **No WAF interaction** ‚Äì HTTP requests are performed with `requests` and a
  descriptive User-Agent, honouring `robots.txt`.
- üì∞ **Multiple draw sources** ‚Äì Parse T13 draw articles and fall back to
  24Horas posts when necessary.
- üí∞ **Pr√≥ximo pozo enrichment** ‚Äì Fetch jackpot estimates from OpenLoto and
  ResultadosLotoChile, keeping provenance metadata.
- üß™ **Deterministic tests** ‚Äì Parsers are covered with fixture-based unit tests.
- üõ†Ô∏è **CLI tooling** ‚Äì Inspect draw URLs, list recent 24Horas posts, and fetch
  pozo estimates directly from the command line.

## Installation

```bash
pip install -r requirements.txt
```

For local development with formatting and linting tools:

```bash
pip install -r requirements-dev.txt
```

## Usage

### End-to-end pipeline (ingest + compare)

Run the multi-source pipeline, write artifacts, and compute a publish decision:

```bash
python -m polla_app run \
  --sources all \
  --retries 3 \
  --timeout 30 \
  --no-fail-fast \
  --raw-dir artifacts/raw \
  --normalized artifacts/normalized.jsonl \
  --comparison-report artifacts/comparison_report.json \
  --summary artifacts/run_summary.json \
  --state-file pipeline_state/last_run.jsonl \
  --log-file logs/run.jsonl \
  --mismatch-threshold 0.2 \
  --include-pozos
```

- Sources: `all` includes `24h` and `t13`. The `24h` URL is auto-discovered (latest); `t13` requires an explicit URL override if you want cross-source comparison.
- Override URLs via `--source-url` (repeatable) or `ALT_SOURCE_URLS` env var (JSON):

```bash
python -m polla_app run \
  --sources all \
  --source-url t13=https://www.t13.cl/noticia/nacional/resultados-del-loto-sorteo-5198

# Or with env var (JSON mapping)
export ALT_SOURCE_URLS='{"t13": "https://www.t13.cl/noticia/..."}'
python -m polla_app run --sources all
```

- Artifacts written under `artifacts/` and decision emitted as `artifacts/comparison_report.json` and `artifacts/run_summary.json`.

### Publish to Google Sheets

```bash
python -m polla_app publish \
  --normalized artifacts/normalized.jsonl \
  --comparison-report artifacts/comparison_report.json \
  --summary artifacts/run_summary.json \
  --worksheet "Normalized" \
  --discrepancy-tab "Discrepancies" \
  --dry-run
```

Environment required:
- `GOOGLE_SHEETS_CREDENTIALS` (service account JSON)
- `GOOGLE_SPREADSHEET_ID` (spreadsheet key)

If the decision status is `quarantine`, the canonical worksheet is skipped and mismatches are written to the discrepancy tab.

### Parse a draw

```bash
python -m polla_app ingest --source t13 "https://www.t13.cl/noticia/nacional/resultados-del-loto-sorteo-5198"
```

- `--source` accepts `t13` (default) or `24h`.
- `--no-pozos` disables pr√≥ximo pozo enrichment.
- `--compact` prints the record on a single JSON line.

### List recent 24Horas result posts

```bash
python -m polla_app list-24h --limit 5
```

### Fetch pr√≥ximo pozo estimates

```bash
python -m polla_app pozos
```

## Data Model

Each draw record emitted by `ingest` follows this schema:

```json
{
  "sorteo": 5322,
  "fecha": "2025-09-16",
  "fuente": "https://www.t13.cl/‚Ä¶",
  "premios": [
    {"categoria": "Loto 6 aciertos", "premio_clp": 0, "ganadores": 0},
    {"categoria": "Quina (5)", "premio_clp": 757970, "ganadores": 3}
  ],
  "pozos_proximo": {
    "Loto Cl√°sico": 690000000,
    "Recargado": 180000000,
    "Total estimado": 4300000000
  },
  "provenance": {
    "source": "t13",
    "url": "https://www.t13.cl/‚Ä¶",
    "ingested_at": "2025-09-17T02:15:00+00:00",
    "pozos": {"primary": {"fuente": "https://resultadoslotochile.com/pozo-para-el-proximo-sorteo/"}}
  }
}
```

## Development

### Tests

```bash
pytest -q
```

### Formatting & Linting

```bash
black polla_app tests
ruff check polla_app tests

## CI

GitHub Actions workflows are provided:

- Ingest + compare + conditional publish: `.github/workflows/scrape.yml`
- Dry-run verification (no publish): `.github/workflows/update.yml`
- Secret checks: `.github/workflows/verify-secret.yml`

Set these in your repository settings:
- Secrets: `GOOGLE_SHEETS_CREDENTIALS`, `GOOGLE_SPREADSHEET_ID`
- Optional Vars: `ALT_SOURCE_URLS` (JSON mapping like `{ "t13": "https://‚Ä¶" }`)

## Migration

This release removes the Playwright-based scraper and switches to an alt-source
HTTP pipeline.

- Replace any `python -m polla_app scrape` calls with `python -m polla_app run`.
- Remove Playwright installation steps from CI (`playwright install`, `install-deps`).
- Ensure repo secrets are configured: `GOOGLE_SHEETS_CREDENTIALS` and `GOOGLE_SPREADSHEET_ID`.
- Optionally set `ALT_SOURCE_URLS` (JSON) to pin source URLs (e.g., a T13 article).
```

## License

MIT
